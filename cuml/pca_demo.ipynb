{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Principal Componenet Analysis (PCA)\n",
    "The PCA algorithm is a dimensionality reduction algorithm which works really well for datasets which have correlated columns. It combines the features of X in linear combination such that the new components capture the most information of the data. \n",
    "The PCA model is implemented in the cuML library and can accept the following parameters: \n",
    "1. svd_solver: selects the type of algorithm used: Jacobi or full (default = full)\n",
    "2. n_components: the number of top K vectors to be present in the output (default = 1)\n",
    "3. random_state: select a random state if the results should be reproducible across multiple runs (default = None)\n",
    "4. copy: if 'True' then it copies the data and removes mean from it else the data will be overwritten with its mean centered version (default = True)\n",
    "5. whiten: if True, de-correlates the components (default = False)\n",
    "6. tol: if the svd_solver = 'Jacobi' then this variable is used to set the tolerance (default = 1e-7)\n",
    "7. iterated_power: if the svd_solver = 'Jacobi' then this variable decides the number of iterations (default = 15)\n",
    "\n",
    "The cuml implementation of the PCA model has the following functions that one can run:\n",
    "1. Fit: it fits the model with the dataset\n",
    "2. Fit_transform: fits the PCA model with the dataset and performs dimensionality reduction on it\n",
    "3. Inverse_transform: returns the original dataset when the transformed dataset is passed as the input\n",
    "4. Transform: performs dimensionality reduction on the dataset\n",
    "5. Get_params: returns the value of the parameters of the PCA model\n",
    "6. Set_params: allows the user to set the value of the parameters of the PCA model\n",
    "\n",
    "The model accepts only numpy arrays or cudf dataframes as the input. In order to convert your dataset to cudf format please read the cudf documentation on https://rapidsai.github.io/projects/cudf/en/latest/. For additional information on the PCA model please refer to the documentation on https://rapidsai.github.io/projects/cuml/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA as skPCA\n",
    "from cuml import PCA as cumlPCA\n",
    "import cudf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the time required by a cell to run\n",
    "from timeit import default_timer\n",
    "\n",
    "class Timer(object):\n",
    "    def __init__(self):\n",
    "        self._timer = default_timer\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.stop()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.start = self._timer()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer. Calculate the interval in seconds.\"\"\"\n",
    "        self.end = self._timer()\n",
    "        self.interval = self.end - self.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the mortgage dataset is present and then extract the data from it, else do not run \n",
    "import gzip\n",
    "def load_data(nrows, ncols, cached = 'data/mortgage.npy.gz'):\n",
    "    if os.path.exists(cached):\n",
    "        print('use mortgage data')\n",
    "        with gzip.open(cached) as f:\n",
    "            X = np.load(f)\n",
    "        X = X[np.random.randint(0,X.shape[0]-1,nrows),:ncols]\n",
    "    else:\n",
    "        # throws FileNotFoundError error if mortgage dataset is not present\n",
    "        raise FileNotFoundError('Please download the required dataset or check the path')\n",
    "    df = pd.DataFrame({'fea%d'%i:X[:,i] for i in range(X.shape[1])})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function checks if the results obtained from two different methods (sklearn and cuml) are the equal\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def array_equal(a,b,threshold=2e-3,with_sign=True):\n",
    "    a = to_nparray(a)\n",
    "    b = to_nparray(b)\n",
    "    if with_sign == False:\n",
    "        a,b = np.abs(a),np.abs(b)\n",
    "    error = mean_squared_error(a,b)\n",
    "    res = error<threshold\n",
    "    return res\n",
    "\n",
    "# the function converts a variable from ndarray or dataframe format to numpy array\n",
    "def to_nparray(x):\n",
    "    if isinstance(x,np.ndarray) or isinstance(x,pd.DataFrame):\n",
    "        return np.array(x)\n",
    "    elif isinstance(x,np.float64):\n",
    "        return np.array([x])\n",
    "    elif isinstance(x,cudf.DataFrame) or isinstance(x,cudf.Series):\n",
    "        return x.to_pandas().values\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# nrows = number of samples\n",
    "# ncols = number of features of each sample\n",
    "\n",
    "nrows = 2**15\n",
    "nrows = int(nrows * 1.5)\n",
    "ncols = 400\n",
    "\n",
    "X = load_data(nrows,ncols)\n",
    "print('data',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for the PCA model\n",
    "n_components = 10\n",
    "whiten = False\n",
    "random_state = 42\n",
    "svd_solver=\"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# use the sklearn PCA on the dataset\n",
    "pca_sk = skPCA(n_components=n_components,svd_solver=svd_solver, \n",
    "            whiten=whiten, random_state=random_state)\n",
    "# creates an embedding\n",
    "result_sk = pca_sk.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# convert the pandas dataframe to cudf dataframe\n",
    "X = cudf.DataFrame.from_pandas(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# use the cuml PCA model on the dataset\n",
    "pca_cuml = cumlPCA(n_components=n_components,svd_solver=svd_solver, \n",
    "            whiten=whiten, random_state=random_state)\n",
    "# obtain the embedding of the model\n",
    "result_cuml = pca_cuml.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the attributes of the two models and compare them\n",
    "for attr in ['singular_values_','components_','explained_variance_',\n",
    "             'explained_variance_ratio_']:\n",
    "    passed = array_equal(getattr(pca_sk,attr),getattr(pca_cuml,attr))\n",
    "    message = 'compare pca: cuml vs sklearn {:>25} {}'.format(attr,'equal' if passed else 'NOT equal')\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the results of the two models\n",
    "passed = array_equal(result_sk,result_cuml)\n",
    "message = 'compare pca: cuml vs sklearn transformed results %s'%('equal'if passed else 'NOT equal')\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
