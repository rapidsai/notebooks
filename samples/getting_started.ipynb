{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with cuDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into a GPU DataFrame (GDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data into a GPU DataFrame\n",
    "\n",
    "It's easy to load almost any sort of data (json, csv, etc) into a GPU DataFrame. Ex (csv import from disk):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv file into pandas dataframe for type definitions\n",
    "df = pd.read_csv('data/ipums/ipums_easy.csv')\n",
    "# create gpu dataframe with types, can be defined manually as well\n",
    "gdf = cudf.read_csv('data/ipums/ipums_easy.csv', names=df.columns.tolist(), dtype=df.dtypes.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the GDF\n",
    "See the [cudf documentation](https://rapidsai.github.io/projects/cudf/en/latest/index.html) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the columns and their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RECTYPE          int64\n",
       "YEAR             int64\n",
       "DATANUM          int64\n",
       "SERIAL           int64\n",
       "NUMPREC          int64\n",
       "SUBSAMP          int64\n",
       "HHWT             int64\n",
       "HHTYPE           int64\n",
       "REPWT          float64\n",
       "CLUSTER          int64\n",
       "ADJUST         float64\n",
       "CPI99          float64\n",
       "REGION           int64\n",
       "STATEICP         int64\n",
       "STATEFIP         int64\n",
       "COUNTY         float64\n",
       "COUNTYFIPS     float64\n",
       "METRO          float64\n",
       "METAREA        float64\n",
       "METAREAD       float64\n",
       "MET2013        float64\n",
       "MET2013ERR     float64\n",
       "CITY           float64\n",
       "CITYERR        float64\n",
       "CITYPOP        float64\n",
       "PUMA           float64\n",
       "PUMARES2MIG    float64\n",
       "STRATA           int64\n",
       "PUMASUPR       float64\n",
       "CONSPUMA       float64\n",
       "                ...   \n",
       "REPWTP51       float64\n",
       "REPWTP52       float64\n",
       "REPWTP53       float64\n",
       "REPWTP54       float64\n",
       "REPWTP55       float64\n",
       "REPWTP56       float64\n",
       "REPWTP57       float64\n",
       "REPWTP58       float64\n",
       "REPWTP59       float64\n",
       "REPWTP60       float64\n",
       "REPWTP61       float64\n",
       "REPWTP62       float64\n",
       "REPWTP63       float64\n",
       "REPWTP64       float64\n",
       "REPWTP65       float64\n",
       "REPWTP66       float64\n",
       "REPWTP67       float64\n",
       "REPWTP68       float64\n",
       "REPWTP69       float64\n",
       "REPWTP70       float64\n",
       "REPWTP71       float64\n",
       "REPWTP72       float64\n",
       "REPWTP73       float64\n",
       "REPWTP74       float64\n",
       "REPWTP75       float64\n",
       "REPWTP76       float64\n",
       "REPWTP77       float64\n",
       "REPWTP78       float64\n",
       "REPWTP79       float64\n",
       "REPWTP80       float64\n",
       "Length: 459, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the columns and their datatypes in this gdf\n",
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice the cuDF dataframe\n",
    "\n",
    "Woah! This GDF has a lot of columns, let's make it more manageable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   INCEARN  PERWT    ADJUST  STATEICP  ROOMS  BEDROOMS  PHONE ...  VETSTAT\n",
      "0 28213070 344826 1930086.0 388083722 374425 203374425 347421 ... 40498806\n",
      "1     4000    618  1.018516        21      7         4      2 ...        1\n",
      "2    36700    684  1.018516        21      7         4      2 ...        1\n",
      "3    54000    618  1.018516        49      5         4      2 ...        2\n",
      "4      900    609  1.018516        49      5         4      2 ...        1\n",
      "[4 more columns]\n"
     ]
    }
   ],
   "source": [
    "# only select certain columns (and overwrite the gdf)\n",
    "gdf = gdf.loc[0:, [\n",
    "    'INCEARN', 'PERWT', 'ADJUST', 'STATEICP', 'ROOMS', 'BEDROOMS',\n",
    "     'PHONE', 'VEHICLES', 'RACE', 'SEX', 'AGE', 'VETSTAT'\n",
    "]]\n",
    "\n",
    "# show the first 5 records of each column\n",
    "print(gdf.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCEARN       int64\n",
       "PERWT         int64\n",
       "ADJUST      float64\n",
       "STATEICP      int64\n",
       "ROOMS         int64\n",
       "BEDROOMS      int64\n",
       "PHONE         int64\n",
       "VEHICLES      int64\n",
       "RACE          int64\n",
       "SEX           int64\n",
       "AGE           int64\n",
       "VETSTAT       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like `INCEARN` and `PERWT` are integers when they should be floats. Let's fix that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCEARN     float64\n",
       "PERWT       float64\n",
       "ADJUST      float64\n",
       "STATEICP      int64\n",
       "ROOMS         int64\n",
       "BEDROOMS      int64\n",
       "PHONE         int64\n",
       "VEHICLES      int64\n",
       "RACE          int64\n",
       "SEX           int64\n",
       "AGE           int64\n",
       "VETSTAT       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# force float64 instead of int64\n",
    "gdf['INCEARN'] = gdf['INCEARN'].astype(np.float64)\n",
    "gdf['PERWT'] = gdf['PERWT'].astype(np.float64)\n",
    "\n",
    "# take another look\n",
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate data with a user-defined function (UDF)\n",
    "\n",
    "`INCEARN` is not a true representation of income earned. Let's adjust it by multiplying it by the `ADJUST` constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40758560323.20648"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to adjust the incearn var\n",
    "# so it more accurately represents income earned\n",
    "adjust = gdf['ADJUST'][0]\n",
    "def adjust_incearn(incearn):\n",
    "    return adjust * incearn;\n",
    "\n",
    "# apply it to the 'population' column\n",
    "gdf['INCEARN'] = gdf['INCEARN'].applymap(adjust_incearn)\n",
    "\n",
    "# drop the ADJUST column\n",
    "gdf.drop_column('ADJUST')\n",
    "\n",
    "# compute the mean\n",
    "gdf['INCEARN'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         INCEARN PERWT STATEICP ROOMS BEDROOMS PHONE VEHICLES ... VETSTAT\n",
      "0 -19298929914.0 538.0       53     4        3     2        2 ...       1\n",
      "1 -19298929914.0 614.0       71     7        4     2        2 ...       1\n",
      "2 -19298929914.0 511.0       45     9        5     2        2 ...       1\n",
      "3 -19298929914.0 453.0       45     9        5     2        2 ...       1\n",
      "4 -19298929914.0 593.0       53     9        5     2        5 ...       1\n",
      "[3 more columns]\n"
     ]
    }
   ],
   "source": [
    "# sort the gdf by the INCEARN column\n",
    "gdf = gdf.sort_values(by='INCEARN')\n",
    "# reset the index so we can use loc slicing later\n",
    "gdf = gdf.reset_index()\n",
    "print(gdf.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some negative income values. Let's filter those out...\n",
    "\n",
    "### Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001 = Original # of records\n",
      "9986 = New # of records\n",
      "  INCEARN PERWT STATEICP ROOMS BEDROOMS PHONE VEHICLES ... VETSTAT\n",
      "15     0.0 559.0       49     5        4     2        3 ...       1\n",
      "16     0.0 589.0       43     8        4     2        3 ...       1\n",
      "17     0.0 617.0       43     5        3     2        1 ...       1\n",
      "18     0.0 574.0       43     6        4     2        1 ...       2\n",
      "19     0.0 616.0       43     6        4     2        1 ...       1\n",
      "[3 more columns]\n"
     ]
    }
   ],
   "source": [
    "# how many records do we have?\n",
    "print(\"{} = Original # of records\".format(len(gdf)))\n",
    "\n",
    "# filter out\n",
    "gdf = gdf.query('INCEARN >= 0')\n",
    "\n",
    "# how many records do we have left?\n",
    "print(\"{} = New # of records\".format(len(gdf)))\n",
    "\n",
    "# sanity check...\n",
    "print(gdf.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCEARN               float64\n",
       "PERWT                 float64\n",
       "ROOMS                   int64\n",
       "BEDROOMS                int64\n",
       "PHONE                   int64\n",
       "VEHICLES                int64\n",
       "AGE                     int64\n",
       "STATEICP_2            float64\n",
       "STATEICP_3            float64\n",
       "STATEICP_4            float64\n",
       "STATEICP_5            float64\n",
       "STATEICP_6            float64\n",
       "STATEICP_11           float64\n",
       "STATEICP_12           float64\n",
       "STATEICP_13           float64\n",
       "STATEICP_14           float64\n",
       "STATEICP_21           float64\n",
       "STATEICP_22           float64\n",
       "STATEICP_23           float64\n",
       "STATEICP_24           float64\n",
       "STATEICP_25           float64\n",
       "STATEICP_31           float64\n",
       "STATEICP_32           float64\n",
       "STATEICP_33           float64\n",
       "STATEICP_34           float64\n",
       "STATEICP_35           float64\n",
       "STATEICP_36           float64\n",
       "STATEICP_37           float64\n",
       "STATEICP_40           float64\n",
       "STATEICP_41           float64\n",
       "                       ...   \n",
       "STATEICP_56           float64\n",
       "STATEICP_61           float64\n",
       "STATEICP_62           float64\n",
       "STATEICP_63           float64\n",
       "STATEICP_64           float64\n",
       "STATEICP_65           float64\n",
       "STATEICP_66           float64\n",
       "STATEICP_67           float64\n",
       "STATEICP_68           float64\n",
       "STATEICP_71           float64\n",
       "STATEICP_72           float64\n",
       "STATEICP_73           float64\n",
       "STATEICP_81           float64\n",
       "STATEICP_82           float64\n",
       "STATEICP_98           float64\n",
       "STATEICP_388083722    float64\n",
       "VETSTAT_1             float64\n",
       "VETSTAT_2             float64\n",
       "VETSTAT_40498806      float64\n",
       "RACE_2                float64\n",
       "RACE_3                float64\n",
       "RACE_4                float64\n",
       "RACE_5                float64\n",
       "RACE_6                float64\n",
       "RACE_7                float64\n",
       "RACE_8                float64\n",
       "RACE_9                float64\n",
       "RACE_35911            float64\n",
       "SEX_2                 float64\n",
       "SEX_3750              float64\n",
       "Length: 72, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the categorical columns\n",
    "cat_cols = set(['STATEICP', 'RACE', 'SEX', 'VETSTAT'])\n",
    "# store the unique values for each category column\n",
    "uniques = {}\n",
    "\n",
    "# iterate through each categorical column and one-hot\n",
    "# encode it using the unique values it has\n",
    "for k in cat_cols:\n",
    "    uniques[k] = gdf[k].unique_k(k=1000)\n",
    "    cats = uniques[k][1:]  # drop first\n",
    "    gdf = gdf.one_hot_encoding(k, prefix=k, cats=cats)\n",
    "    del gdf[k]\n",
    "    \n",
    "# we should see many more columns since the categorical\n",
    "# columns will get expanded due to one-hot encoding\n",
    "gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitpoint: 0.8 of 9986 is 7988\n",
      "gdfs[\"train\"] has 7974 rows\n",
      "gdfs[\"valid\"] has 2013 rows\n"
     ]
    }
   ],
   "source": [
    "# enforce float64 data type on ALL columns\n",
    "for k in gdf.columns:\n",
    "    gdf[k] = gdf[k].astype(np.float64)\n",
    "\n",
    "# set the fractions for training and validation\n",
    "fractions = {\n",
    "    \"train\": 0.8,\n",
    "    \"valid\": 0.2\n",
    "}\n",
    "\n",
    "# validation splitpoint\n",
    "splitpoint = int(len(gdf) * fractions[\"train\"])\n",
    "print('splitpoint: {} of {} is {}'.format(fractions[\"train\"], len(gdf), splitpoint))\n",
    "\n",
    "# break the gdf up into training, validation, and test sets\n",
    "gdfs = {\n",
    "    \"train\": gdf.loc[:splitpoint],\n",
    "    \"valid\": gdf.loc[splitpoint:]\n",
    "}\n",
    "print('gdfs[\"train\"] has {} rows'.format(len(gdfs[\"train\"])))\n",
    "print('gdfs[\"valid\"] has {} rows'.format(len(gdfs[\"valid\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn the GDFs into matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrices[\"train\"][\"x\"] shape: (7974, 71)\n",
      "matrices[\"train\"][\"y\"] shape: (7974, 1)\n",
      "matrices[\"valid\"][\"x\"] shape: (2013, 71)\n",
      "matrices[\"valid\"][\"y\"] shape: (2013, 1)\n"
     ]
    }
   ],
   "source": [
    "# produce gpu matrices (to input to ml libraries, etc)\n",
    "# this step should not be necessary in the near future\n",
    "# (should be able to use gdf as input)\n",
    "matrices = {\n",
    "    \"train\": {\n",
    "        \"x\": gdfs[\"train\"].as_gpu_matrix(columns=gdf.columns[1:]),\n",
    "        \"y\": gdfs[\"train\"].as_gpu_matrix(columns=[gdf.columns[0]])\n",
    "    },\n",
    "    \"valid\": {\n",
    "        \"x\": gdfs[\"valid\"].as_gpu_matrix(columns=gdf.columns[1:]),\n",
    "        \"y\": gdfs[\"valid\"].as_gpu_matrix(columns=[gdf.columns[0]])\n",
    "    }\n",
    "}\n",
    "\n",
    "# check the matrix shapes (sanity check)\n",
    "print('matrices[\"train\"][\"x\"] shape:', matrices[\"train\"][\"x\"].shape)\n",
    "print('matrices[\"train\"][\"y\"] shape:', matrices[\"train\"][\"y\"].shape)\n",
    "print('matrices[\"valid\"][\"x\"] shape:', matrices[\"valid\"][\"x\"].shape)\n",
    "print('matrices[\"valid\"][\"y\"] shape:', matrices[\"valid\"][\"y\"].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
